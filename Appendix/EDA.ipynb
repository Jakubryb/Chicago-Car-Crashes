{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "This notebook illustrates detailed download and cleaning of the Chicago Crash data. \n",
    "\n",
    "Our Problem focused on what factors contribute to **severe** traffic incidents at **night**. \n",
    "\n",
    "* **Severe** traffic incidents we defined as `FATAL` or `INCAPACITATING` from the `INJURY_TYPE` column. \n",
    "\n",
    "* **Night** we defined as the hours between 10pm to 5 am, or hours `22` through `5` in the `CRASH_HOUR` column. \n",
    "\n",
    "* Final output is `final_df` which will be used in the following notebook(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Neccessary Packages and CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the neccessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df = pd.read_csv('data/Traffic_Crashes_-_crashes.csv')\n",
    "people_df = pd.read_csv('data/Traffic_Crashes_-_people.csv', low_memory=False)\n",
    "vehicle_df = pd.read_csv('data/Traffic_Crashes_-_vehicles.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneccessary Columns\n",
    "\n",
    "#### `crash_df` dropping Justification: \n",
    "\n",
    "* `RD_NO` - Police Dep. Report number, another identifying number associated with each record, we kept `CRASH_RECORD_ID` as the joining record number for each dataframe. \n",
    "* `CRASH_DATE_EST_I` - used when crash is reported to police days after the crash, this dataframe inclues crash day of week, hour and month so we can drop the specific date.\n",
    "* `CRASH_DATE` - this dataframe inclues crash day of week, hour and month so we can drop the specific date.\n",
    "* `REPORT_TYPE` - administrative report type, not a factor relevant to causing a crash.\n",
    "* `HIT_AND_RUN_I` - not a factor relevant to causing a crash.\n",
    "* `DATE_POLICE_NOTIFIED` - not a factor relevant to causing a crash.\n",
    "* `STREET_NO` - of location related data we chose to keep latitude, longitude\n",
    "* `BEAT_OF_OCCURENCE` - not a factor relevant to causing a crash.\n",
    "* `PHOTOS_TAKEN_I` - not a factor relevant to causing a crash.\n",
    "* `STATEMENTS_TAKEN` - not a factor relevant to causing a crash.\n",
    "* `MOST_SEVERE_INJURY` - basing our severity of injury off of information from the `people_df` dataframe, including this and other injury related columns would cause multicolliniarity in our modeling. \n",
    "* `INJURIES_FATAL`\n",
    "* `INJURIES_NON_INCAPACITATING`\n",
    "* `INJURIES_REPORTED_NOT_EVIDENT`\n",
    "* `INJURIES_NO_INDICATION`\n",
    "* `INJURIES_UNKNOWN`\n",
    "* `LONGITUDE`\n",
    "* `LATITUDE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df_dropped = crash_df[['CRASH_RECORD_ID', 'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION', \n",
    "                                          'WEATHER_CONDITION', 'LIGHTING_CONDITION', 'LANE_CNT', \n",
    "                                          'ROADWAY_SURFACE_COND', 'ROAD_DEFECT', 'NOT_RIGHT_OF_WAY_I',\n",
    "                                          'PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE', \n",
    "                                          'DOORING_I','WORK_ZONE_I', 'WORK_ZONE_TYPE', 'WORKERS_PRESENT_I', \n",
    "                                          'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `people_df` dropping Justification: \n",
    "\n",
    "* `PERSON_ID` - unique ID for each person record, \n",
    "\n",
    "... do we need to fill in reasons for all these? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_dropped = people_df[['CRASH_RECORD_ID', 'PERSON_TYPE', 'AGE', 'DRIVERS_LICENSE_STATE',\n",
    "                                'DRIVER_ACTION', 'DRIVER_VISION', 'BAC_RESULT VALUE', \n",
    "                                'INJURY_CLASSIFICATION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `vehicle_df` dropping Justification: \n",
    "\n",
    "* `---`, \n",
    "\n",
    "... do we need to fill in reasons for all these? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_df_dropped = vehicle_df[['CRASH_RECORD_ID', 'VEHICLE_YEAR', 'MANEUVER']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting crash records between 10 pm and 5 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_time_df = crash_df_dropped.copy()\n",
    "night_time_df = night_time_df[(night_time_df['CRASH_HOUR'] >= 22) | (night_time_df['CRASH_HOUR'] <= 6)]\n",
    "night_time_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining all three data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape\n",
    "night_time_df.shape, people_df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(night_time_df, people_df_dropped, how='left', on='CRASH_RECORD_ID')\n",
    "merge1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploring Columns\n",
    "\n",
    "#### `INJURY_CLASSIFICATION` target Variable - this includes all people involved in incident, cyclists, passengers, drivers, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1['INJURY_CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatal / incapacitate = 1\n",
    "merge1.loc[(merge1['INJURY_CLASSIFICATION'] == 'FATAL') | \n",
    "           (merge1['INJURY_CLASSIFICATION'] == 'INCAPACITATING INJURY'), 'INJURY_CLASSIFICATION'] = '1'\n",
    "\n",
    "# else = 0\n",
    "merge1.loc[(merge1['INJURY_CLASSIFICATION'] == 'NO INDICATION OF INJURY') | \n",
    "           (merge1['INJURY_CLASSIFICATION'] == 'NONINCAPACITATING INJURY') |\n",
    "           (merge1['INJURY_CLASSIFICATION'] == 'REPORTED, NOT EVIDENT'), 'INJURY_CLASSIFICATION'] = '0'\n",
    "\n",
    "merge1['INJURY_CLASSIFICATION'].fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1[\"INJURY_CLASSIFICATION\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merge1.copy()\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the `final_df` into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = final_df.to_csv('clean_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with the target as the first column,\n",
    "# then compute the correlation matrix\n",
    "corr = final_df.corr()\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 15))\n",
    "\n",
    "# Plot a heatmap of the correlation matrix, with both\n",
    "# numbers and colors indicating the correlations\n",
    "sns.heatmap(\n",
    "    # Specifies the data to be plotted\n",
    "    data=corr,\n",
    "    # The mask means we only show half the values,\n",
    "    # instead of showing duplicates. It's optional.\n",
    "    mask=np.triu(np.ones_like(corr, dtype=bool)),\n",
    "    # Specifies that we should use the existing axes\n",
    "    ax=ax,\n",
    "    # Specifies that we want labels, not just colors\n",
    "    annot=True,\n",
    "    # Customizes colorbar appearance\n",
    "    cbar_kws={\"label\": \"Correlation\", \"orientation\": \"horizontal\", \"pad\": .2, \"extend\": \"both\"}\n",
    ")\n",
    "\n",
    "# Customize the plot appearance\n",
    "ax.set_title(\"Heatmap of Correlation Between Attributes (Including Target)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c15d3b161d9e31d3c14101c293414707f40e59d6cae0bbd6b708ca3d1e942f6f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
