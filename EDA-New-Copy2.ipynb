{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "This notebook illustrates detailed download and cleaning of the Chicago Crash data. \n",
    "\n",
    "Our Problem focused on what factors contribute to **severe** traffic incidents for just drivers at **night**. \n",
    "\n",
    "* **Severe** traffic incidents we defined as `FATAL` or `INCAPACITATING` from the `INJURY_TYPE` column. \n",
    "\n",
    "* **Night** we defined as the hours between 10pm to 5 am, or hours `22` through `5` in the `CRASH_HOUR` column. \n",
    "\n",
    "* Final output is `final_df` which will be used in the following notebook(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Neccessary Packages and CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the neccessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report, plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, classification_report\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df = pd.read_csv('data/Traffic_Crashes_-_crashes.csv')\n",
    "people_df = pd.read_csv('data/Traffic_Crashes_-_people.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneccessary Columns\n",
    "\n",
    "#### `crash_df` dropping Justification: \n",
    "\n",
    "* `RD_NO` - Police Dep. Report number, another identifying number associated with each record, we kept `CRASH_RECORD_ID` as the joining record number for each dataframe. \n",
    "* `CRASH_DATE_EST_I` - used when crash is reported to police days after the crash, this dataframe inclues crash day of week, hour and month so we can drop the specific date.\n",
    "* `CRASH_DATE` - this dataframe inclues crash day of week, hour and month so we can drop the specific date.\n",
    "* `REPORT_TYPE` - administrative report type, not a factor relevant to causing a crash.\n",
    "* `HIT_AND_RUN_I` - not a factor relevant to causing a crash.\n",
    "* `DATE_POLICE_NOTIFIED` - not a factor relevant to causing a crash.\n",
    "* `STREET_NO` - of location related data we chose to keep latitude, longitude\n",
    "* `BEAT_OF_OCCURENCE` - not a factor relevant to causing a crash.\n",
    "* `PHOTOS_TAKEN_I` - not a factor relevant to causing a crash.\n",
    "* `STATEMENTS_TAKEN` - not a factor relevant to causing a crash.\n",
    "* `MOST_SEVERE_INJURY` - basing our severity of injury off of information from the `people_df` dataframe, including this and other injury related columns would cause multicolliniarity in our modeling. \n",
    "* `INJURIES_FATAL`\n",
    "* `INJURIES_NON_INCAPACITATING`\n",
    "* `INJURIES_REPORTED_NOT_EVIDENT`\n",
    "* `INJURIES_NO_INDICATION`\n",
    "* `INJURIES_UNKNOWN`\n",
    "* `LONGITUDE`\n",
    "* `LATITUDE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 554228 entries, 0 to 554227\n",
      "Data columns (total 49 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   CRASH_RECORD_ID                554228 non-null  object \n",
      " 1   RD_NO                          549766 non-null  object \n",
      " 2   CRASH_DATE_EST_I               41950 non-null   object \n",
      " 3   CRASH_DATE                     554228 non-null  object \n",
      " 4   POSTED_SPEED_LIMIT             554228 non-null  int64  \n",
      " 5   TRAFFIC_CONTROL_DEVICE         554228 non-null  object \n",
      " 6   DEVICE_CONDITION               554228 non-null  object \n",
      " 7   WEATHER_CONDITION              554228 non-null  object \n",
      " 8   LIGHTING_CONDITION             554228 non-null  object \n",
      " 9   FIRST_CRASH_TYPE               554228 non-null  object \n",
      " 10  TRAFFICWAY_TYPE                554228 non-null  object \n",
      " 11  LANE_CNT                       198970 non-null  float64\n",
      " 12  ALIGNMENT                      554228 non-null  object \n",
      " 13  ROADWAY_SURFACE_COND           554228 non-null  object \n",
      " 14  ROAD_DEFECT                    554228 non-null  object \n",
      " 15  REPORT_TYPE                    540273 non-null  object \n",
      " 16  CRASH_TYPE                     554228 non-null  object \n",
      " 17  INTERSECTION_RELATED_I         125851 non-null  object \n",
      " 18  NOT_RIGHT_OF_WAY_I             26204 non-null   object \n",
      " 19  HIT_AND_RUN_I                  167405 non-null  object \n",
      " 20  DAMAGE                         554228 non-null  object \n",
      " 21  DATE_POLICE_NOTIFIED           554228 non-null  object \n",
      " 22  PRIM_CONTRIBUTORY_CAUSE        554228 non-null  object \n",
      " 23  SEC_CONTRIBUTORY_CAUSE         554228 non-null  object \n",
      " 24  STREET_NO                      554228 non-null  int64  \n",
      " 25  STREET_DIRECTION               554224 non-null  object \n",
      " 26  STREET_NAME                    554227 non-null  object \n",
      " 27  BEAT_OF_OCCURRENCE             554223 non-null  float64\n",
      " 28  PHOTOS_TAKEN_I                 6872 non-null    object \n",
      " 29  STATEMENTS_TAKEN_I             11233 non-null   object \n",
      " 30  DOORING_I                      1795 non-null    object \n",
      " 31  WORK_ZONE_I                    3478 non-null    object \n",
      " 32  WORK_ZONE_TYPE                 2752 non-null    object \n",
      " 33  WORKERS_PRESENT_I              865 non-null     object \n",
      " 34  NUM_UNITS                      554227 non-null  float64\n",
      " 35  MOST_SEVERE_INJURY             553087 non-null  object \n",
      " 36  INJURIES_TOTAL                 553098 non-null  float64\n",
      " 37  INJURIES_FATAL                 553098 non-null  float64\n",
      " 38  INJURIES_INCAPACITATING        553098 non-null  float64\n",
      " 39  INJURIES_NON_INCAPACITATING    553098 non-null  float64\n",
      " 40  INJURIES_REPORTED_NOT_EVIDENT  553098 non-null  float64\n",
      " 41  INJURIES_NO_INDICATION         553098 non-null  float64\n",
      " 42  INJURIES_UNKNOWN               553098 non-null  float64\n",
      " 43  CRASH_HOUR                     554228 non-null  int64  \n",
      " 44  CRASH_DAY_OF_WEEK              554228 non-null  int64  \n",
      " 45  CRASH_MONTH                    554228 non-null  int64  \n",
      " 46  LATITUDE                       551029 non-null  float64\n",
      " 47  LONGITUDE                      551029 non-null  float64\n",
      " 48  LOCATION                       551029 non-null  object \n",
      "dtypes: float64(12), int64(5), object(32)\n",
      "memory usage: 207.2+ MB\n"
     ]
    }
   ],
   "source": [
    "crash_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    42587\n",
       "15    42326\n",
       "17    41653\n",
       "14    37575\n",
       "18    34490\n",
       "13    34297\n",
       "12    32896\n",
       "8     28751\n",
       "11    28532\n",
       "9     25573\n",
       "10    25327\n",
       "19    25290\n",
       "7     23174\n",
       "20    20244\n",
       "21    18065\n",
       "22    16648\n",
       "23    14129\n",
       "6     12268\n",
       "0     11546\n",
       "1      9847\n",
       "2      8404\n",
       "5      7521\n",
       "3      6842\n",
       "4      6243\n",
       "Name: CRASH_HOUR, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_df['CRASH_HOUR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df_cleaned = crash_df[['CRASH_RECORD_ID', 'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION', \n",
    "                             #'LATITUDE', 'LONGITUDE',\n",
    "                             'WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND', \n",
    "                             'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `people_df` dropping Justification: \n",
    "\n",
    "* `PERSON_ID` - unique ID for each person record, \n",
    "\n",
    "... do we need to fill in reasons for all these? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df_cleaned = people_df[['CRASH_RECORD_ID', 'AGE', \n",
    "                               'BAC_RESULT VALUE', 'INJURY_CLASSIFICATION', 'PERSON_TYPE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting crash records between 10 pm and 6 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRASH_RECORD_ID', 'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION',\n",
       "       'WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND',\n",
       "       'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "night_time_df = crash_df_cleaned.copy()\n",
    "#night_time_df = night_time_df[(night_time_df['CRASH_HOUR'] >= 22) | (night_time_df['CRASH_HOUR'] <= 6)]\n",
    "night_time_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE                                 353351\n",
       "UNKNOWN                              234396\n",
       "FAILED TO YIELD                       89917\n",
       "OTHER                                 84309\n",
       "FOLLOWED TOO CLOSELY                  62148\n",
       "IMPROPER BACKING                      30836\n",
       "IMPROPER TURN                         25741\n",
       "IMPROPER LANE CHANGE                  25627\n",
       "IMPROPER PASSING                      21591\n",
       "DISREGARDED CONTROL DEVICES           16374\n",
       "TOO FAST FOR CONDITIONS               15674\n",
       "IMPROPER PARKING                       3758\n",
       "WRONG WAY/SIDE                         3754\n",
       "CELL PHONE USE OTHER THAN TEXTING      1608\n",
       "EVADING POLICE VEHICLE                 1596\n",
       "OVERCORRECTED                          1198\n",
       "EMERGENCY VEHICLE ON CALL               924\n",
       "TEXTING                                 425\n",
       "STOPPED SCHOOL BUS                      113\n",
       "LICENSE RESTRICTIONS                     44\n",
       "Name: DRIVER_ACTION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_df['DRIVER_ACTION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change1end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining all two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((554228, 9), (1226112, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape\n",
    "night_time_df.shape, people_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225784, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = pd.merge(night_time_df, people_df_cleaned, how='left', on='CRASH_RECORD_ID')\n",
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 25.0     25220\n",
       " 26.0     24959\n",
       " 27.0     24753\n",
       " 28.0     24208\n",
       " 24.0     24187\n",
       "          ...  \n",
       "-47.0         1\n",
       "-49.0         1\n",
       " 106.0        1\n",
       "-177.0        1\n",
       "-40.0         1\n",
       "Name: AGE, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge['AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploring Columns\n",
    "\n",
    "#### `INJURY_CLASSIFICATION` target Variable - this includes all people involved in incident, cyclists, passengers, drivers, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO INDICATION OF INJURY     1122230\n",
       "NONINCAPACITATING INJURY      57052\n",
       "REPORTED, NOT EVIDENT         32978\n",
       "INCAPACITATING INJURY         11118\n",
       "FATAL                           682\n",
       "Name: INJURY_CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge['INJURY_CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatal / incapacitate = 1\n",
    "merge.loc[(merge['INJURY_CLASSIFICATION'] == 'FATAL') | \n",
    "           (merge['INJURY_CLASSIFICATION'] == 'INCAPACITATING INJURY') | \n",
    "           (merge['INJURY_CLASSIFICATION'] == 'NONINCAPACITATING INJURY') |\n",
    "           (merge['INJURY_CLASSIFICATION'] == 'REPORTED, NOT EVIDENT'), 'INJURY_CLASSIFICATION'] = 1\n",
    "\n",
    "# else = 0\n",
    "merge.loc[(merge['INJURY_CLASSIFICATION'] == 'NO INDICATION OF INJURY'), 'INJURY_CLASSIFICATION'] = 0\n",
    "\n",
    "merge['INJURY_CLASSIFICATION'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1123954\n",
       "1     101830\n",
       "Name: INJURY_CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge[\"INJURY_CLASSIFICATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.916927\n",
       "1    0.083073\n",
       "Name: INJURY_CLASSIFICATION, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge[\"INJURY_CLASSIFICATION\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'False: boolean label can not be used without a boolean index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8632/377093915.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCrash_Injury\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"INJURY_CLASSIFICATION\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[1;31m# boolean not in slice and with boolean index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m             raise KeyError(\n\u001b[0m\u001b[0;32m    973\u001b[0m                 \u001b[1;34mf\"{key}: boolean label can not be used without a boolean index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m             )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'False: boolean label can not be used without a boolean index'"
     ]
    }
   ],
   "source": [
    "Crash_Injury= merge.loc[[\"INJURY_CLASSIFICATION\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.drop(columns=['CRASH_RECORD_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing traffic control device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.loc[merge['TRAFFIC_CONTROL_DEVICE'] == 'NO CONTROLS', 'TRAFFIC_CONTROL_DEVICE'] = 0\n",
    "merge.loc[merge['TRAFFIC_CONTROL_DEVICE'] != 0, 'TRAFFIC_CONTROL_DEVICE'] = 1\n",
    "\n",
    "merge.loc[merge.DEVICE_CONDITION == 'FUNCTIONING PROPERLY', 'DEVICE_CONDITION'] = 1\n",
    "merge.loc[merge.DEVICE_CONDITION != 1, 'DEVICE_CONDITION'] = 0\n",
    "\n",
    "merge['DEVICE_CONDITION'] = merge['DEVICE_CONDITION'].astype(float)\n",
    "merge['TRAFFIC_CONTROL_DEVICE'] = merge['TRAFFIC_CONTROL_DEVICE'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is clear\n",
    "merge.loc[merge['WEATHER_CONDITION'] == 'CLEAR', 'WEATHER_CONDITION'] = 1\n",
    "\n",
    "# 0 is not clear\n",
    "merge.loc[merge['WEATHER_CONDITION'] != 1, 'WEATHER_CONDITION'] = 0\n",
    "\n",
    "merge['WEATHER_CONDITION'] = merge['WEATHER_CONDITION'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing lighting condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe this during train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['LIGHTING_CONDITION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing roadway surface cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.loc[merge['ROADWAY_SURFACE_COND'] == 'OTHER', 'ROADWAY_SURFACE_COND'] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['ROADWAY_SURFACE_COND'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.loc[merge['AGE'] <= 0, 'AGE'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.dropna(subset=['AGE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.loc[merge['PERSON_TYPE'] == 'DRIVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(list(merge['AGE'].value_counts().index), merge['AGE'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop(columns=['PERSON_TYPE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing bac_result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge.rename(columns={'BAC_RESULT VALUE':'BAC_RESULT_VALUE'})\n",
    "\n",
    "merge['BAC_RESULT VALUE'].fillna(0, inplace=True)\n",
    "\n",
    "# 1 value is drunk\n",
    "merge.loc[merge['BAC_RESULT VALUE'] >= 0.08, 'BAC_RESULT VALUE'] = 1\n",
    "\n",
    "# 0 value is non drunk\n",
    "merge.loc[merge['BAC_RESULT VALUE'] < 0.08, 'BAC_RESULT VALUE'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning weekends and weekday nights\n",
    "\n",
    "# 1 value is a weekend night\n",
    "merge.loc[merge['CRASH_DAY_OF_WEEK'] >= 6, 'CRASH_DAY_OF_WEEK'] = 1\n",
    "\n",
    "# 0 value is a weekday night\n",
    "merge.loc[merge['CRASH_DAY_OF_WEEK'] != 1, 'CRASH_DAY_OF_WEEK'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing lane count (deprecated)\n",
    "\n",
    "dropping because too many null values that we don't want to skew data with mean/median, and don't want to assume a distribution for synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = merge[merge['LANE_CNT'] > 12].index\n",
    "\n",
    "# merge.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge['LANE_CNT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge['LANE_CNT'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.bar(list(merge['LANE_CNT'].value_counts().index), merge['LANE_CNT'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge['LANE_CNT'].fillna(merge['LANE_CNT'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.bar(list(merge['LANE_CNT'].value_counts().index), merge['LANE_CNT'].value_counts().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = merge.copy()\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the `final_df` into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data = final_df.to_csv('clean_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['INJURY_CLASSIFICATION'])\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "#under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=11))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'classifier__max_depth':[1, 3, 5]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted = grid_search.best_score_\n",
    "test_score_smoted = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_smoted, test_score_smoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote over and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['INJURY_CLASSIFICATION'])\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=11))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'classifier__max_depth':[1, 3, 5]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(grid_search.best_params_)\n",
    "cv_score_smoted = grid_search.best_score_\n",
    "test_score_smoted = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=11, max_depth=5))\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "feature_list = pipeline['col_transformer'].get_feature_names()\n",
    "plot_tree(pipeline['classifier'], ax=ax, feature_names=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted, test_score_smoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['INJURY_CLASSIFICATION'])\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "\n",
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=11))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'classifier__max_depth':[1, 3, 5]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_no_smote = grid_search.best_score_\n",
    "test_score_no_smoted = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_no_smote, test_score_no_smoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (just traffic control device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['TRAFFIC_CONTROL_DEVICE']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "#    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['INJURY_CLASSIFICATION'])\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train,\n",
    "                                          random_state=42,\n",
    "                                          test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('knn_classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'knn_classifier__n_neighbors': [3,5,9],\n",
    "               'knn_classifier__metric': ['minkowski']}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_t, y_t)\n",
    "\n",
    "y_hat = grid_search.predict(X_val)\n",
    "print(grid_search.best_params_)\n",
    "cv_score_smoted_knn = grid_search.best_score_\n",
    "test_score_smoted_knn = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_knn, test_score_smoted_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(grid_search, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['INJURY_CLASSIFICATION'])\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, road cond, age, traffic control device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'AGE', 'TRAFFIC_CONTROL_DEVICE', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (without age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (traffic control device, surface cond, day of week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'CRASH_DAY_OF_WEEK']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (traffic control device, crash day of week, roadway cond, weather cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'CRASH_DAY_OF_WEEK']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (traffic control device, crash day of week, roadway cond, weather cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'CRASH_DAY_OF_WEEK']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (traffic control device, crash day of week, roadway cond, weather cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'CRASH_DAY_OF_WEEK', 'WEATHER_CONDITION']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, roadway, traffic control, lighting, crash hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'TRAFFIC_CONTROL_DEVICE', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, roadway, device cond, lighting, crash hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR', 'DEVICE_CONDITION']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'logistic_regressor__max_iter': [50, 100, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, roadway, device cond, lighting, crash hour) tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR', 'DEVICE_CONDITION']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "                'logistic_regressor__max_iter': [100, 150, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2'],\n",
    "               'logistic_regressor__solver': ['newton-cg', 'lbfgs', 'sag']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(grid_search.best_params_)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, roadway, device cond, lighting, crash hour, crash month) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR', 'DEVICE_CONDITION', 'CRASH_MONTH']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42, max_iter=250))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "              # 'logistic_regressor__max_iter': [100, 150, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2'],\n",
    "               'logistic_regressor__solver': ['newton-cg', 'lbfgs', 'sag']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(grid_search.best_params_)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote logistic regression (weather, roadway, device cond, lighting, crash hour, bac_result value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[['WEATHER_CONDITION', 'ROADWAY_SURFACE_COND', 'LIGHTING_CONDITION',\n",
    "             'CRASH_HOUR', 'DEVICE_CONDITION', 'BAC_RESULT VALUE']]\n",
    "y = final_df['INJURY_CLASSIFICATION']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), ['LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='not minority')\n",
    "\n",
    "# Create a pipeline containing the column transformer and model\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('col_transformer', col_transformer),\n",
    "    ('o', over),\n",
    "    ('u', under),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic_regressor', LogisticRegression(random_state=42, max_iter=250))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "              # 'logistic_regressor__max_iter': [100, 150, 250, 500],\n",
    "              # 'logistic_regressor__C': [1e-10, 1e-100],\n",
    "               'logistic_regressor__penalty': ['none', 'l2'],\n",
    "               'logistic_regressor__solver': ['newton-cg', 'lbfgs', 'sag']\n",
    "              }]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5\n",
    "                           )\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(grid_search.best_params_)\n",
    "cv_score_smoted_log = grid_search.best_score_\n",
    "test_score_smoted_log = grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_smoted_log, test_score_smoted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c15d3b161d9e31d3c14101c293414707f40e59d6cae0bbd6b708ca3d1e942f6f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
